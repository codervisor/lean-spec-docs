---
id: 'agent-configuration'
title: 'Agent Configuration'
sidebar_position: 2
---
# Agent Configuration

Configure AI coding agents to work effectively with LeanSpec through AGENTS.md instructions and best practices.

## AGENTS.md Overview

`AGENTS.md` serves as permanent instructions for AI coding agents in your repository. When you run `lean-spec init`, this file is created with LeanSpec guidance.

**Purpose:**
- Provide context about your project
- Define when to use specs
- Specify workflow and commands
- Set quality standards

## Complete AGENTS.md Template

```markdown
# AI Agent Instructions

## Project: [Your Project Name]

[Brief description of what the project does]

## First Principles (Decision Framework)

When making spec decisions, apply these principles in priority order:

### 1. Context Economy - Fit in working memory
**Specs must fit in working memory‚Äîboth human and AI.**
- **Target**: <2,000 tokens per spec file
- **Warning**: 2,000-3,500 tokens (acceptable but watch complexity)
- **Problem**: >3,500 tokens (consider splitting)

### 2. Signal-to-Noise Maximization - Every word informs decisions
**Every word must inform decisions or be cut.**
- **Test**: "What decision does this sentence inform?"
- **Cut**: Obvious, inferable, or "maybe future" content

### 3. Intent Over Implementation - Capture why, not just how
**Capture "why" and "what," let "how" emerge.**
- **Must have**: Problem, intent, success criteria
- **Should have**: Design rationale, trade-offs

### 4. Bridge the Gap - Both human and AI must understand
**Specs exist to align human intent with machine execution.**
- **For humans**: Overview, context, rationale
- **For AI**: Unambiguous requirements, clear structure, examples

### 5. Progressive Disclosure - Add complexity when pain is felt
**Start simple, add structure only when pain is felt.**
- **Solo dev**: Just status + created
- **Feel pain?**: Add tags, priority, custom fields

## Core Rules

1. **Read README.md first** - Understand project context
2. **Check specs/** - Review existing specs before starting
3. **Use `lean-spec --help`** - When unsure about commands
4. **Follow LeanSpec principles** - Clarity over documentation
5. **Keep it minimal** - If it doesn't add clarity, cut it
6. **NEVER manually edit system-managed frontmatter** - Use CLI commands instead

## When to Use Specs

Write a spec for:
- Features affecting multiple parts of the system
- Breaking changes or significant refactors
- Design decisions needing team alignment

Skip specs for:
- Bug fixes
- Trivial changes
- Self-explanatory refactors

## Essential Commands

**Discovery:**
- `lean-spec list` - See all specs
- `lean-spec search "<query>"` - Find relevant specs
- `lean-spec board` - Kanban view with project health
- `lean-spec stats` - Quick project metrics

**Working with specs:**
- `lean-spec create <name>` - Create new spec
- `lean-spec update <spec> --status <status>` - Update status (REQUIRED)
- `lean-spec link <spec> --related <other>` - Link specs
- `lean-spec deps <spec>` - Show dependency graph
- `lean-spec tokens <spec>` - Count tokens for context management

## Spec Relationships

### `related` - Bidirectional Soft Reference
Informational relationship between specs. Automatically shown from both sides.
**Use when:** Specs cover related topics, work is coordinated but not blocking.

### `depends_on` - Directional Blocking Dependency
Hard dependency - spec cannot start until dependencies complete.
**Use when:** Spec truly cannot start until another completes, work order matters.

## SDD Workflow

1. **Discover** - Check existing specs with `lean-spec list`
2. **Plan** - Create spec with `lean-spec create <name>` (status: `planned`)
3. **Start Work** - Run `lean-spec update <spec> --status in-progress` before implementing
4. **Implement** - Write code/docs, keep spec in sync as you learn
5. **Complete** - Run `lean-spec update <spec> --status complete` after implementation done

**CRITICAL - What "Work" Means:**
- ‚ùå **NOT**: Creating/writing the spec document itself
- ‚úÖ **YES**: Implementing what the spec describes (code, docs, features, etc.)

## Quality Standards

- Code is clear and maintainable
- Tests cover critical paths
- Specs stay in sync with implementation
- **Status tracking is mandatory:**
  - Specs start as `planned` after creation
  - Mark `in-progress` BEFORE starting implementation work
  - Mark `complete` AFTER implementation is finished
- **Always validate before completing work:**
  - Run `lean-spec validate` to check spec structure
  - Fix any validation errors before marking work complete

## Spec Complexity Guidelines

**Token Thresholds:**
- **<2,000 tokens**: ‚úÖ Optimal
- **2,000-3,500 tokens**: ‚úÖ Good
- **3,500-5,000 tokens**: ‚ö†Ô∏è Warning - Consider splitting
- **>5,000 tokens**: üî¥ Should split

**Check with:** `lean-spec tokens <spec>`
```

## Configuring Different AI Tools

### GitHub Copilot

Copilot automatically reads `AGENTS.md` when files are opened in your editor.

**No additional setup needed.**

### Cursor

Cursor reads `.cursorrules` by default. Options:

**Option 1:** Use AGENTS.md (recommended)
```bash
# Cursor also reads AGENTS.md
# No additional setup
```

**Option 2:** Link .cursorrules to AGENTS.md
```bash
ln -s AGENTS.md .cursorrules
```

### Windsurf

Add to your Windsurf config:

```json
{
  "systemPrompt": "Read and follow instructions in AGENTS.md"
}
```

### Claude, ChatGPT, Other Chat Interfaces

Reference AGENTS.md in your initial prompt:

```
Read the AGENTS.md file in this repository and follow 
its instructions for working with LeanSpec specs.
```

## Best Practices for AI-Readable Specs

### 1. Be Explicit and Concrete

‚ùå **Vague:**
```markdown
Implement secure authentication
```

‚úÖ **Specific:**
```markdown
Implement JWT authentication with:
- bcrypt password hashing (min 10 rounds)
- 24-hour token expiry
- Rate limiting (5 attempts/min per IP)
```

### 2. Provide Examples

AI agents understand examples better than abstract descriptions.

**Good:**
```markdown
## API Response Example

```json
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "expiresAt": "2025-11-03T06:00:00Z",
  "user": {
    "id": "user_123",
    "email": "user@example.com"
  }
}
```
```

### 3. Use Testable Acceptance Criteria

Make criteria specific and verifiable:

‚úÖ **Good Criteria:**
- [ ] POST /api/auth/login returns 200 with JWT on success
- [ ] Invalid credentials return 401 with error message
- [ ] Passwords are hashed with bcrypt, min 10 rounds
- [ ] Rate limit: max 5 attempts per minute per IP

‚ùå **Bad Criteria:**
- [ ] Authentication works
- [ ] Good security
- [ ] Fast performance

### 4. Define Boundaries Explicitly

Use "Out of Scope" or "Non-Goals" to prevent scope creep:

```markdown
## Out of Scope

- Social login (Google, GitHub) - separate epic
- Password reset - separate spec
- 2FA - not needed for MVP
- Remember me functionality - future enhancement
```

### 5. Show, Don't Just Tell

Include concrete examples of:
- API requests/responses
- CLI commands and output
- Database schemas
- Configuration files
- Test cases

### 6. Structure for Scanning

AI agents (and humans) scan before reading:

‚úÖ **Good Structure:**
```markdown
## Problem
[2-3 sentences]

## Solution
[High-level approach]

### Technical Details
[Implementation specifics]

## Success Criteria
- [ ] [Testable outcome]
```

‚ùå **Bad Structure:**
```markdown
So we need to build this feature and it should do X, Y, Z...
[wall of text with no structure]
```

## Repository Organization

### Make Specs Discoverable

```
your-project/
‚îú‚îÄ‚îÄ AGENTS.md           ‚Üê AI reads this first
‚îú‚îÄ‚îÄ README.md           ‚Üê Project overview
‚îú‚îÄ‚îÄ specs/              ‚Üê All specs here
‚îÇ   ‚îú‚îÄ‚îÄ 001-feature-a/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ 002-feature-b/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DESIGN.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TESTING.md
‚îÇ   ‚îî‚îÄ‚îÄ archived/       ‚Üê Old specs
‚îú‚îÄ‚îÄ src/                ‚Üê Source code
‚îî‚îÄ‚îÄ tests/              ‚Üê Tests
```

### Keep Specs Close to Code

Specs in the repo (not external wiki):
- ‚úÖ Version controlled
- ‚úÖ Branch-specific
- ‚úÖ Easy for AI to find
- ‚úÖ Searchable

## Verification

### Test AI Understanding

Ask your AI agent:

**Test 1: Can it find specs?**
```
List all specs in this repository.
```
Expected: Agent uses `lean-spec list`

**Test 2: Can it read specs?**
```
What does spec 001 describe?
```
Expected: Agent uses `lean-spec view 001`

**Test 3: Can it follow workflow?**
```
Create a spec for user authentication.
```
Expected: Agent uses `lean-spec create user-authentication`

**Test 4: Can it update status?**
```
Mark spec 001 as in-progress.
```
Expected: Agent uses `lean-spec update 001 --status in-progress`

## Common Pitfalls

### 1. Overly Verbose Instructions

‚ùå **Bad:**
```markdown
The AI agent should carefully read all available documentation
and thoroughly understand the codebase before making any changes.
It's important to...
[500 words of general advice]
```

‚úÖ **Good:**
```markdown
1. Read README.md first
2. Check existing specs with `lean-spec list`
3. Follow LeanSpec principles (see AGENTS.md)
```

### 2. Ambiguous Success Criteria

‚ùå **Bad:**
```markdown
- [ ] Feature works well
- [ ] Good performance
- [ ] Users are happy
```

‚úÖ **Good:**
```markdown
- [ ] API response <100ms (p95)
- [ ] Zero crashes in 1 week
- [ ] NPS score >8
```

### 3. Missing Context

Always provide:
- **Why**: Problem and motivation
- **What**: Specific requirements
- **How**: Approach and constraints
- **When**: Success criteria

## Next Steps

- [MCP Integration](/docs/guide/usage/ai-assisted/mcp-integration) - Model Context Protocol setup
- [Writing Specs AI Can Execute](/docs/guide/usage/ai-assisted/ai-executable-patterns) - 12 practical patterns
- [Getting Started](/docs/guide/getting-started) - Initial setup guide

---

**Related**: [CLI Reference](/docs/reference/cli) for complete command documentation
